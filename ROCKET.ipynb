{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c6989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the file path before running it\n",
    "def load_ae_data(train_file='/Users/admin/Desktop/Code/data/ae.train', test_file='/Users/admin/Desktop/Code/data/ae.test'):\n",
    "    \"\"\"\n",
    "    Load and parse the ape call data from ASCII files.\n",
    "    \n",
    "    Returns:\n",
    "    - train_inputs: list of numpy arrays (270 time series, each N x 12)\n",
    "    - test_inputs: list of numpy arrays (370 time series, each N x 12) \n",
    "    - train_outputs: list of numpy arrays (270 time series, each N x 9)\n",
    "    - test_outputs: list of numpy arrays (370 time series, each N x 9)\n",
    "    - N is the length of the time series, varying per sample\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the data\n",
    "    ae_train = np.loadtxt(train_file)\n",
    "    ae_test = np.loadtxt(test_file)\n",
    "    \n",
    "    # Parse training data\n",
    "    train_inputs = []\n",
    "    read_index = 0\n",
    "    \n",
    "    for c in range(270):\n",
    "        start_index = read_index\n",
    "        # Find the length of current time series (until we hit a row of 1.0s)\n",
    "        while read_index < len(ae_train) and ae_train[read_index, 0] != 1.0:\n",
    "            read_index += 1\n",
    "        \n",
    "        # Extract the time series\n",
    "        time_series = ae_train[start_index:read_index, :]\n",
    "        train_inputs.append(time_series)\n",
    "        \n",
    "        # Skip the separator row of 1.0s\n",
    "        read_index += 1\n",
    "    \n",
    "    # Parse test data\n",
    "    test_inputs = []\n",
    "    read_index = 0\n",
    "    \n",
    "    for c in range(370):\n",
    "        start_index = read_index\n",
    "        # Find the length of current time series\n",
    "        while read_index < len(ae_test) and ae_test[read_index, 0] != 1.0:\n",
    "            read_index += 1\n",
    "        \n",
    "        # Extract the time series\n",
    "        time_series = ae_test[start_index:read_index, :]\n",
    "        test_inputs.append(time_series)\n",
    "        \n",
    "        # Skip the separator row of 1.0s\n",
    "        read_index += 1\n",
    "    \n",
    "    # Generate teacher signals (outputs)\n",
    "    train_outputs = []\n",
    "    for c in range(270):\n",
    "        length = len(train_inputs[c])\n",
    "        teacher = np.zeros((length, 9))\n",
    "        speaker_index = c // 30  # 30 samples per speaker, 9 speakers total\n",
    "        teacher[:, speaker_index] = 1\n",
    "        train_outputs.append(teacher)\n",
    "    \n",
    "    test_outputs = []\n",
    "    speaker_index = 0\n",
    "    block_counter = 0\n",
    "    block_lengths = [31, 35, 88, 44, 29, 24, 40, 50, 29]  # samples per speaker in test set\n",
    "    \n",
    "    for c in range(370):\n",
    "        if block_counter == block_lengths[speaker_index]:\n",
    "            speaker_index += 1\n",
    "            block_counter = 0\n",
    "        \n",
    "        length = len(test_inputs[c])\n",
    "        teacher = np.zeros((length, 9))\n",
    "        teacher[:, speaker_index] = 1\n",
    "        test_outputs.append(teacher)\n",
    "        \n",
    "        block_counter += 1\n",
    "    \n",
    "    return train_inputs, test_inputs, train_outputs, test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('/Users/admin/Desktop/Code/data', exist_ok=True)\n",
    "\n",
    "# Load the data\n",
    "train_inputs, test_inputs, train_outputs, test_outputs = load_ae_data()\n",
    "\n",
    "# Save the data as separate pickle files\n",
    "with open('/Users/admin/Desktop/Code/data/train_inputs.pkl', 'wb') as f:\n",
    "    pickle.dump(train_inputs, f)\n",
    "with open('/Users/admin/Desktop/Code/data/test_inputs.pkl', 'wb') as f:\n",
    "    pickle.dump(test_inputs, f)\n",
    "with open('/Users/admin/Desktop/Code/data/train_outputs.pkl', 'wb') as f:\n",
    "    pickle.dump(train_outputs, f)\n",
    "with open('/Users/admin/Desktop/Code/data/test_outputs.pkl', 'wb') as f:\n",
    "    pickle.dump(test_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eccc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_data(data_folder='/Users/admin/Desktop/Code/data'):\n",
    "    \"\"\"\n",
    "    Load the preprocessed ape call data from pickle files.\n",
    "    \n",
    "    Args:\n",
    "        data_folder (str): Path to the folder containing pickle files\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (train_inputs, test_inputs, train_outputs, test_outputs)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(f'{data_folder}/train_inputs.pkl', 'rb') as f:\n",
    "            train_inputs = pickle.load(f)\n",
    "        with open(f'{data_folder}/test_inputs.pkl', 'rb') as f:\n",
    "            test_inputs = pickle.load(f)\n",
    "        with open(f'{data_folder}/train_outputs.pkl', 'rb') as f:\n",
    "            train_outputs = pickle.load(f)\n",
    "        with open(f'{data_folder}/test_outputs.pkl', 'rb') as f:\n",
    "            test_outputs = pickle.load(f)\n",
    "        \n",
    "        print(f\"Data loaded successfully from {data_folder}/\")\n",
    "        print(f\"Train samples: {len(train_inputs)}, Test samples: {len(test_inputs)}\")\n",
    "        print(f\"Input dimensions: {train_inputs[0].shape[1]}, Output dimensions: {train_outputs[0].shape[1]}\")\n",
    "        \n",
    "        return train_inputs, test_inputs, train_outputs, test_outputs\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701cd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, test_inputs, train_outputs, test_outputs = load_saved_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f807b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the maximum length for the trainning data set\n",
    "def max_Len(input_data):\n",
    "    length = [i.shape[0] for i in input_data]\n",
    "    return int(max(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50594d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding\n",
    "def padding_to_maxl(input_data,max_l):\n",
    "    padding_data = []\n",
    "    for i in input_data:\n",
    "        Time_step, LPC = i.shape\n",
    "        if Time_step >= max_l:\n",
    "            padding = i[:max_l]\n",
    "        else:\n",
    "            padding = np.pad(i, ((0,max_l-Time_step),(0,0)), mode=\"constant\", constant_values=0.0)\n",
    "        padding_data.append(padding)\n",
    "    return np.stack(padding_data,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879763e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Length = max_Len(train_inputs)\n",
    "padding_train_data = padding_to_maxl(train_inputs, Length)\n",
    "padding_test_data = padding_to_maxl(test_inputs, Length)\n",
    "\n",
    "print(f\"padding train input: {padding_train_data.shape}\")\n",
    "print(f\"padding test input: {padding_test_data.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
